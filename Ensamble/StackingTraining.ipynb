{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackingTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I_x3NmRV54pO",
        "5Se4ul5BqQRY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "KPPQdtsLVMU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Rh0-B1krVMU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from models import *\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Input, Dropout, Convolution1D, MaxPool1D, UpSampling1D, concatenate, GlobalMaxPool1D\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "A10BmhdlVMU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up GPU"
      ],
      "metadata": {
        "id": "H0aMAPRMVMU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != \"/device:GPU:0\":\n",
        "  device_name = \"/cpu:0\"\n",
        "print('Found device at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "PW2CMIpnVMU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Folder Structure"
      ],
      "metadata": {
        "id": "XN7eeWpgVMVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path(\"../input/\")\n",
        "model_dir = Path(\"./\")\n",
        "base_dir = Path(\"../\")"
      ],
      "metadata": {
        "id": "-f7rZyjxVMVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "I_x3NmRV54pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "format_data is a utility function for relaibly loading and lightly formatting the heartbeat data signals. It can add padding to ensure that signals have a certain lenght."
      ],
      "metadata": {
        "id": "rZvUjple6CaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  :param df: Dataframe containing signal and labels\n",
        "  :param padded_size: Integer indicating if signal should be padded\n",
        "                      to certain length\n",
        "  :return: Signal, Labels\n",
        "\"\"\"\n",
        "def format_data(\n",
        "    df : pd.DataFrame,\n",
        "    padded_size : Optional[int] = None\n",
        ") -> Tuple[np.array, np.array]:\n",
        "\n",
        "    # Load signal and labels from the dataframe\n",
        "    Y = np.array(df[187].values).astype(np.int8)\n",
        "    X = np.array(df[list(range(187))].values)[..., np.newaxis]\n",
        "\n",
        "    # Add padding if padded_size is specified\n",
        "    if not padded_size is None:\n",
        "        X = np.concatenate([X, np.zeros((X.shape[0], padded_size - X.shape[1], 1))], axis=1)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "4EKp0_Cw5szg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct Stacking Ensambles"
      ],
      "metadata": {
        "id": "5Se4ul5BqQRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "construct_ensamble is a utility function to train and test a stacking ensamble based on averaging predicted probabilities, voting and using a logistic regression on top of the predicted probabilities."
      ],
      "metadata": {
        "id": "69YkkMcDsSp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  :param pretrined_models: Pretrained models to stack\n",
        "  :param X_train: Training signals\n",
        "  :param Y_train: Training labels\n",
        "  :param X_test: Test signals\n",
        "  :param Y_test: Test labels\n",
        "  :param multiclass: \n",
        "\"\"\"\n",
        "def construct_ensamble(pretrined_models, X_train, Y_train, X_test, Y_test, multiclass):\n",
        "    \n",
        "    # Ensamble types to test\n",
        "    ensamble_types = [\n",
        "        (\"Mean Ensamble\", MeanEnsamble), \n",
        "        (\"Voting Ensamble\", VotingEnsamble), \n",
        "        (\"Logistic Regression Ensamble\", LogRegEnsamble)\n",
        "    ]\n",
        "\n",
        "    # Iterate over all ensamble types\n",
        "    for name, ensamble_type in ensamble_types:\n",
        "\n",
        "        print(f\"Fitting a {name}\")\n",
        "\n",
        "        model = ensamble_type(pretrined_models)\n",
        "        model.fit(X_train, Y_train)\n",
        "\n",
        "        pred_test = model.predict(X_test)\n",
        "\n",
        "        if multiclass:\n",
        "            f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
        "            print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "            acc = accuracy_score(Y_test, pred_test)\n",
        "            print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "        else:\n",
        "\n",
        "            f1 = f1_score(Y_test, pred_test)\n",
        "            print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "            acc = accuracy_score(Y_test, pred_test)\n",
        "            print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "            auroc = roc_auc_score(Y_test, pred_test)\n",
        "            print(\"Test AUROC : %s \"% auroc)\n",
        "\n",
        "            auprc = average_precision_score(Y_test, pred_test)\n",
        "            print(\"Test AUPRC : %s \"% auprc)\n",
        "\n",
        "        print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "AS1beDWmqrPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PTB Dataset"
      ],
      "metadata": {
        "id": "3xUKbLgn-UZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "WLAgRi9JEwca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the data using the previously defined utility functions"
      ],
      "metadata": {
        "id": "n-OPYzJFrrVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem parameters\n",
        "unpadded_size = 187\n",
        "padded_size = 256\n",
        "\n",
        "# Load data PTB\n",
        "df_1 = pd.read_csv(data_dir.joinpath(\"ptbdb_normal.csv\"), header=None)\n",
        "df_2 = pd.read_csv(data_dir.joinpath(\"ptbdb_abnormal.csv\"), header=None)\n",
        "df   = pd.concat([df_1, df_2])\n",
        "\n",
        "df_train, df_test = train_test_split(\n",
        "    df, test_size=0.2, \n",
        "    random_state=1337, stratify=df[unpadded_size]\n",
        ")\n",
        "\n",
        "# Format data\n",
        "X_test, Y_test   = format_data(df_test)\n",
        "X_train, Y_train = format_data(df_train)\n"
      ],
      "metadata": {
        "id": "whbwoD5z9161"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up pretrained models"
      ],
      "metadata": {
        "id": "CO6j9UtNIO-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses  import mean_squared_error\n",
        "\n",
        "# Load the U-Net seperatly before loading the other pre-trained models\n",
        "encoder = Unet((padded_size,1), loss = mean_squared_error)\n",
        "encoder.initialize(np.zeros([1, padded_size, 1]), np.zeros([1, padded_size, 1]))\n",
        "encoder.load_weights(\"/content/ml4healthproject1/FinishedModels/unet.h5\")"
      ],
      "metadata": {
        "id": "22tozbHvKXsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained models\n",
        "pretrained_models = [\n",
        "    (\n",
        "        DoubleConvCNN(classes=1, dropout=0.1, optimizer=Adam(learning_rate = 0.001)),\n",
        "        base_dir.joinpath(\"CNNs/Results/VanillaCNN_PTBDB.h5\")\n",
        "    ),\n",
        "\n",
        "    (\n",
        "        ResNetStandard(classes=1, filters=32, dropout=0.1, optimizer=RMSprop(1e-3)),\n",
        "        base_dir.joinpath(\"CNNs/Results/ResNet_ptbdb.h5\")\n",
        "    ),\n",
        "    (\n",
        "        LatentClassifier(classes = 1, width=128, depth=2, encoder=encoder, padded_size=padded_size),\n",
        "        base_dir.joinpath(\"Unet/latent_ptbdb.h5\")\n",
        "    ),\n",
        "    (\n",
        "        VanillaRNN(input_length=X_train.shape[1], num_units=200, classes=2, num_cells = 1, dropout=0.2, optimizer=\"adam\", lr=0.0001),\n",
        "        base_dir.joinpath(\"RNNs/Results/final_vanilla_rnn_ptbdb.h5\")\n",
        "    ),\n",
        "    (\n",
        "        BiDirLSTM(input_length=X_train.shape[1], num_units=100, classes=2, num_cells = 2, num_dense = 2, dropout=0, optimizer=\"adam\", lr=0.0001),\n",
        "        base_dir.joinpath(\"RNNs/Results/final_bdlstm_ptbdb.h5\")\n",
        "    ),\n",
        "    (\n",
        "        ConvLSTM(input_length=X_train.shape[1], num_units=150, num_conv=2, num_dense = 2, classes=2, dropout=0.5, optimizer=\"adam\", lr=0.00),\n",
        "        base_dir.joinpath(\"/RNNs/Results/final_cnn_lstm_ptbdb.h5\")\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "JRtsbnExITVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct ensambles based on all previously trained models and also just the CNN models"
      ],
      "metadata": {
        "id": "qUaAf1XYsuvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test stacking all previously trained models\n",
        "print(\"Testing all models\\n\")\n",
        "construct_ensamble(\n",
        "    pretrained_models,\n",
        "    X_train, Y_train,\n",
        "    X_test, Y_test,\n",
        "    False\n",
        ")\n",
        "\n",
        "# Test stacking only the top performing models\n",
        "# based on their CV-scores during training\n",
        "print(\"Testing using only top three models\\n\")\n",
        "construct_ensamble(\n",
        "    pretrained_models[:3],\n",
        "    X_train, Y_train,\n",
        "    X_test, Y_test,\n",
        "    False\n",
        ")\n"
      ],
      "metadata": {
        "id": "Jpk45_S9s1uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIT-BIH Dataset"
      ],
      "metadata": {
        "id": "HW9_PwxZudp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "XFQYLgbXudp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the data using the previously defined utility functions"
      ],
      "metadata": {
        "id": "5nu5RH5yudp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem parameters\n",
        "unpadded_size = 187\n",
        "padded_size = 256\n",
        "\n",
        "# Load data MIT\n",
        "df_train = pd.read_csv(data_dir.joinpath(\"mitbih_train.csv\"), header=None)\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_test = pd.read_csv(data_dir.joinpath(\"mitbih_test.csv\"), header=None)\n",
        "\n",
        "# Format data\n",
        "X_test, Y_test   = format_data(df_test)\n",
        "X_train, Y_train = format_data(df_train)\n"
      ],
      "metadata": {
        "id": "kFMO5X8Xudp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up pretrained models"
      ],
      "metadata": {
        "id": "NZefKXoqudp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses  import mean_squared_error\n",
        "\n",
        "# Load the U-Net seperatly before loading the other pre-trained models\n",
        "encoder = Unet((padded_size,1), loss = mean_squared_error)\n",
        "encoder.initialize(np.zeros([1, padded_size, 1]), np.zeros([1, padded_size, 1]))\n",
        "encoder.load_weights(\"/content/ml4healthproject1/FinishedModels/unet.h5\")"
      ],
      "metadata": {
        "id": "_ZpxNaV2udp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained models\n",
        "pretrained_models = [\n",
        "    (\n",
        "        VanillaCNN(classes=5, dropout=0.1, optimizer=Adam(learning_rate = 0.001)),\n",
        "        base_dir.joinpath(\"CNNs/Results/VanillaCNN_MITBIH.h5\")\n",
        "    ),\n",
        "\n",
        "    (\n",
        "        ResNetStandard(classes=5, filters=32, dropout=0.1, optimizer=RMSprop(1e-3)),\n",
        "        base_dir.joinpath(\"CNNs/Results/ResNet_MITBIH.h5\")\n",
        "    ),\n",
        "    (\n",
        "        LatentClassifier(classes = 5, width=128, depth=2, encoder=encoder, padded_size=padded_size),\n",
        "        base_dir.joinpath(\"Unet/latent_mitbih.h5\")\n",
        "    ),\n",
        "    (\n",
        "        VanillaRNN(input_length=X_train.shape[1], num_units=150, classes=5, num_cells = 1, dropout=0.2, optimizer=\"adam\", lr=5e-05),\n",
        "        base_dir.joinpath(\"RNNs/Results/final_vanilla_rnn_mitbih.h5\")\n",
        "    ),\n",
        "    (\n",
        "        BiDirLSTM(input_length=X_train.shape[1], num_units=100, classes=5, num_cells = 2,  num_dense = 2, dropout=0, optimizer=\"adam\", lr=0.0001),\n",
        "        base_dir.joinpath(\"RNNs/Results/final_bdlstm_mitbih.h5\")\n",
        "    ),\n",
        "    (\n",
        "        ConvLSTM(input_length=X_train.shape[1], num_units=150, num_conv=2, num_dense = 2, classes=5, dropout=0.5, optimizer=\"adam\", lr=0.001),\n",
        "        base_dir.joinpath(\"RNNs/Results/final_cnn_lstm_mitbih.h5\")\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "Vr2eM_1budp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct ensambles based on all previously trained models and also just the CNN models"
      ],
      "metadata": {
        "id": "uQIZT4Ljudp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test stacking all previously trained models\n",
        "print(\"Testing all models\\n\")\n",
        "construct_ensamble(\n",
        "    pretrained_models,\n",
        "    X_train, Y_train,\n",
        "    X_test, Y_test,\n",
        "    True\n",
        ")\n",
        "\n",
        "# Test stacking only the top performing models\n",
        "# based on their CV-scores during training\n",
        "print(\"Testing using only top three models\\n\")\n",
        "construct_ensamble(\n",
        "    pretrained_models[:3],\n",
        "    X_train, Y_train,\n",
        "    X_test, Y_test,\n",
        "    True\n",
        ")\n"
      ],
      "metadata": {
        "id": "V26MeArPudp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}