{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67715bf2",
   "metadata": {},
   "source": [
    "# Task 1 and 2 - RNN Based Models\n",
    "\n",
    "This notebook includes the training and testing of the finalised RNN based models. All models except for LSTM converge, their hyperparameters are selected in the RNN_Models_Hyperparam_Search.ipynb notebook. \n",
    "\n",
    "## Model Comparison:\n",
    "-------------------------------------------------------------------\n",
    "### Vanilla RNN:\n",
    "#### PTB:\n",
    "Test f1 score : 0.9515545914678236  \\\n",
    "Test accuracy score : 0.9309515630367571  \\\n",
    "Test AUROC score : 0.9244353779260203  \\\n",
    "Test AUPRC score : 0.9495864255421855 \n",
    "\n",
    "#### MIT:\n",
    "Test f1 score : 0.8582  \\\n",
    "Test accuracy score : 0.9728 \n",
    "\n",
    "\n",
    "-------------------------------------------------------------------\n",
    "### LSTM: - almost only predicts majority class - no convergence\n",
    "#### PTB:\n",
    "Test f1 score : 0.8386195890684222  \\\n",
    "Test accuracy score : 0.7220886293369976  \\\n",
    "Test AUROC score : 0.5  \\\n",
    "Test AUPRC score : 0.7220886293369976  \n",
    "\n",
    "#### MIT:\n",
    "Test f1 score : 0.1863665513376111  \\\n",
    "Test accuracy score : 0.8282477617394483 \n",
    "\n",
    "-------------------------------------------------------------------\n",
    "### Bidirectional LSTM:\n",
    "#### PTB:\n",
    "Test f1 score : 0.9663291735342595 \\\n",
    "Test accuracy score : 0.9508759876331158\\\n",
    "Test AUROC score : 0.9306281968200277 \\\n",
    "Test AUPRC score : 0.9510640339196088\n",
    "\n",
    "#### MIT:\n",
    "Test f1 score : 0.8917068203921733  \\\n",
    "Test accuracy score : 0.978211218710031 \n",
    "\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "### ConvLSTM:\n",
    "#### PTB:\n",
    "Test f1 score : 0.9827218934911243 \\\n",
    "Test accuracy score : 0.9749227069735487  \\\n",
    "Test AUROC score : 0.9647672062277494  \\\n",
    "Test AUPRC score : 0.9746978178291369 \n",
    "\n",
    "#### MIT:\n",
    "Test f1 score : 0.9076935070124723  \\\n",
    "Test accuracy score : 0.9828704549607162  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71457fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "import model_helper\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models import *\n",
    "\n",
    "\n",
    "# To ensure reproducable results: \n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1af196",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != \"/device:GPU:0\":\n",
    "  device_name = \"/cpu:0\"\n",
    "print('Found device at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d246d",
   "metadata": {},
   "source": [
    "# MIT-BIH Arryhtmia Database\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de59879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y_mitbih = np.array(df_train[187].values).astype(np.int8)\n",
    "X_mitbih = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test_mitbih = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test_mitbih = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee89ea9",
   "metadata": {},
   "source": [
    "# PTB Diagonstic ECG Database\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../input/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../input/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y_ptbdb = np.array(df_train[187].values).astype(np.int8)\n",
    "X_ptbdb = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test_ptbdb = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test_ptbdb = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7148e9",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "# Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b2ee9",
   "metadata": {},
   "source": [
    "All final models incorporating a version of RNNs are trained and tested in the following sections to specify final performance metrics. Model hyperparameters were chosen through hyperparameter search as displayed in the notebook: RNN_Models_Hyperparam_Search.ipynb\n",
    "\n",
    "\n",
    "# Vanilla RNN\n",
    "***************************************\n",
    "Since Vanilal RNN performance on validations sets during hyperparameter search varied greatly accross runs, we run the final Vanilla RNN models 5 times and obtain average evaluation metrics and their standard deviaton.\n",
    "\n",
    "## PTB Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_vanilla_rnn_ptbdb.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b036f68",
   "metadata": {},
   "source": [
    "### To test the saved model file without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ec102",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    model = None\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb,\n",
    "                                 binary_task=True, train=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bb22f",
   "metadata": {},
   "source": [
    "### To train and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67ec42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "    model = VanillaRNN( input_length=X_ptbdb.shape[1], num_units=150, classes=2,  \n",
    "                                        num_cells = 1, dropout=0, optimizer=\"adam\", callbacks= callbacks_list, lr=0.0001)\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb,\n",
    "                                 binary_task=True, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c5e91",
   "metadata": {},
   "source": [
    "## MIT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_vanilla_rnn_mitbih.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e1879",
   "metadata": {},
   "source": [
    "### To test the saved model file without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    model = None\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, train=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91ca73",
   "metadata": {},
   "source": [
    "### To train and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "    model = VanillaRNN( input_length=X_mitbih.shape[1], num_units=150, classes=5,  \n",
    "                                        num_cells = 1, dropout=0.2, optimizer=\"adam\",callbacks= callbacks_list, lr=5e-05)\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, save_name = save_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d1ab5",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM - does not converge\n",
    "***************************************\n",
    "\n",
    "## PTB Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5eb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_lstm_ptbdb.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "\n",
    "    model = VanillaLSTM( input_length=X_ptbdb.shape[1], num_units=150, classes=2, num_cells = 1, num_dense = 2,\n",
    "                        dropout=0, optimizer=\"adam\", callbacks= callbacks_list, lr=0.01)\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb, \n",
    "                                  binary_task=True, save_name = save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2cbd9",
   "metadata": {},
   "source": [
    "## MIT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da222a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_lstm_mitbih.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7759832",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "\n",
    "    model = VanillaLSTM( input_length=X_ptbdb.shape[1], num_units=150, classes=5, num_cells = 1, \n",
    "                        dropout=0, optimizer=\"adam\", callbacks= callbacks_list, lr=0.0001)\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9ef17",
   "metadata": {},
   "source": [
    "\n",
    "# Bidirectional LSTM \n",
    "***************************************\n",
    "\n",
    "## PTB Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f931311",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_bdlstm_ptbdb.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617a4e9",
   "metadata": {},
   "source": [
    "### To test the saved model file without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6eecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    model = None\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb,\n",
    "                                 binary_task=True, train=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dda9bc",
   "metadata": {},
   "source": [
    "### To train and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "    model = BiDirLSTM( input_length=X_ptbdb.shape[1], num_units=100, classes=2, num_cells = 2, \n",
    "                        num_dense = 2, dropout=0, optimizer=\"adam\", callbacks= callbacks_list,lr=0.0001)\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb,\n",
    "                                 binary_task=True, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2f390",
   "metadata": {},
   "source": [
    "## MIT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_bdlstm_mitbih.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3e591",
   "metadata": {},
   "source": [
    "### To test the saved model file without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    model = None\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, train=False,save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb74e4c8",
   "metadata": {},
   "source": [
    "### To train and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5303125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "    model = BiDirLSTM( input_length=X_mitbih.shape[1], num_units=100, classes=5, num_cells = 2, \n",
    "                        num_dense = 2, dropout=0, optimizer=\"adam\",callbacks= callbacks_list, lr=0.0001)\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9ab68",
   "metadata": {},
   "source": [
    "\n",
    "# ConvLSTM \n",
    "***************************************\n",
    "\n",
    "## PTB Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4edff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_cnn_lstm_ptbdb.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56498a09",
   "metadata": {},
   "source": [
    "### To test the saved model file without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    model = None\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb,\n",
    "                                 binary_task=True, train=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cf4a3",
   "metadata": {},
   "source": [
    "### To train and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "    model = ConvLSTM( input_length=X_ptbdb.shape[1], num_units=150, num_conv=2, num_dense = 2,\n",
    "                       classes=2, dropout=0.5, optimizer=\"adam\",callbacks= callbacks_list, lr=0.001)\n",
    "\n",
    "    model_helper.train_test_model( model, X_ptbdb, Y_ptbdb, X_test_ptbdb, Y_test_ptbdb,\n",
    "                                 binary_task=True, save_name = save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33fca9",
   "metadata": {},
   "source": [
    "## MIT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"Results/final_cnn_lstm_mitbih.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd5f47",
   "metadata": {},
   "source": [
    "### To test the saved model file without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    model = None\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, train=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a4ffb",
   "metadata": {},
   "source": [
    "### To train and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aca96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "    \n",
    "    #callbacks to stop or change learning rate when held out validation set loss \n",
    "    #stops improving, patience selected high due to instability of RNNs\n",
    "    early = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, verbose=1)\n",
    "    if save_name:\n",
    "        checkpoint = ModelCheckpoint(filepath=save_name, monitor='val_loss', verbose=1, save_best_only=True) \n",
    "        callbacks_list = [checkpoint, early, redonplat] \n",
    "    else:\n",
    "        callbacks_list = [early, redonplat] \n",
    "    \n",
    "    #creating and trainin model\n",
    "    model = ConvLSTM( input_length=X_mitbih.shape[1], num_units=150, num_conv=2, num_dense = 2,\n",
    "                       classes=5, dropout=0.5, optimizer=\"adam\", callbacks= callbacks_list,lr=0.001)\n",
    "\n",
    "    model_helper.train_test_model( model, X_mitbih, Y_mitbih, X_test_mitbih, Y_test_mitbih,\n",
    "                                 binary_task=False, save_name = save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383cd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
