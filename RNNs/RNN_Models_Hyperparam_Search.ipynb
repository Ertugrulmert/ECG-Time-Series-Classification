{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e65241e",
   "metadata": {},
   "source": [
    "# Hyperparam Grid Search for RNN Models\n",
    "---------------------------------------------------------\n",
    "\n",
    "In this notebook, hyperparameter grid search using 5-fold cross validation accuracy is carried out for all RNN based models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b90fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "import model_helper\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models import *\n",
    "\n",
    "\n",
    "# To ensure reproducable results: \n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for GPU for speed-up\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != \"/device:GPU:0\":\n",
    "  device_name = \"/cpu:0\"\n",
    "print('Found device at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748c2bf",
   "metadata": {},
   "source": [
    "# MIT-BIH Arryhtmia Database\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y_mitbih = np.array(df_train[187].values).astype(np.int8)\n",
    "X_mitbih = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test_mitbih = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test_mitbih = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a8b30",
   "metadata": {},
   "source": [
    "# PTB Diagonstic ECG Database\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c52f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../input/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../input/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y_ptbdb = np.array(df_train[187].values).astype(np.int8)\n",
    "X_ptbdb = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test_ptbdb = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test_ptbdb = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea789c",
   "metadata": {},
   "source": [
    "\n",
    "# Vanilla RNN\n",
    "***************************************\n",
    "Grid search code for both datasets and both Vanilla RNN and LSTM based models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a239512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_grid_search(name=\"ptb\", model = \"vanilla\"):\n",
    "\n",
    "    #optimizer and other unit number options were discarded as grid search takes too long\n",
    "    unit_nums = [ 100, 150]\n",
    "    dropout_rate = [0,0.2, 0.4]\n",
    "    learning_rates = [0.0001, 0.00005, 0.000075]\n",
    "    batch = 200\n",
    "    epochs = 100\n",
    "    optim = \"adam\"\n",
    "\n",
    "    opt_params = {}\n",
    "    best_AUC = 0\n",
    "    best_acc = 0\n",
    "    scores = []\n",
    "    \n",
    "    (X,Y) = (X_ptbdb, Y_ptbdb) if name==\"ptb\" else (X_mitbih, Y_mitbih)\n",
    "\n",
    "    for drop in dropout_rate:\n",
    "        for units in unit_nums:\n",
    "            for lr in learning_rates:\n",
    "                        print(\"---------------------------------------------------\")\n",
    "                        print(\"Params to evaluate:\")\n",
    "                        print(\"LR: \",lr, \" | Units: \", units, \" | Dropout: \",drop, \" | Optim: \",optim)\n",
    "\n",
    "                        scores = []\n",
    "\n",
    "                        for train, val in KFold(n_splits=5, shuffle=True).split(X,Y):\n",
    "                            \n",
    "                                print(\"Fold - \", len(scores)+1)\n",
    "\n",
    "                                #callbacks enable early stopping and learning rate reduction\n",
    "                                #depending on validation loss\n",
    "                                early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=15, verbose=1)\n",
    "                                redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=10, verbose=1)\n",
    "                                callbacks_list = [early, redonplat]\n",
    "                                \n",
    "                                with tf.device(device_name):\n",
    "                                \n",
    "                                    # initializing the model\n",
    "                                    #depending on dataset, number of classes determined\n",
    "                                    if model == \"vanilla\":\n",
    "                                        if name == \"ptb\": \n",
    "                                            model = VanillaRNN(input_length=X[train].shape[1], \n",
    "                                                               num_units=units, classes=2, callbacks= callbacks_list,\n",
    "                                                               optimizer = optim, dropout= drop, lr=lr)    \n",
    "                                        else:\n",
    "                                            model = VanillaRNN(input_length=X[train].shape[1], \n",
    "                                                               num_units=units, classes=5, callbacks= callbacks_list,\n",
    "                                                               optimizer = optim, dropout= drop, lr=lr)  \n",
    "                                    elif model == \"lstm\":\n",
    "                                        if name == \"ptb\": \n",
    "                                            model = VanillaLSTM(input_length=X[train].shape[1], \n",
    "                                                                num_units=units, classes=2, callbacks= callbacks_list,\n",
    "                                                                optimizer = optim, dropout= drop, lr=lr)    \n",
    "                                        else:\n",
    "                                            model = VanillaLSTM(input_length=X[train].shape[1], \n",
    "                                                                num_units=units, classes=5, callbacks= callbacks_list,\n",
    "                                                                optimizer = optim, dropout= drop, lr=lr)  \n",
    "\n",
    "\n",
    "                                    # training the model\n",
    "                                    model.fit(X[train], Y[train], epochs=epochs, batch_size=batch, \n",
    "                                            verbose=0, validation_data = (X[val],Y[val]) )\n",
    "\n",
    "                                    # evaluate validation set\n",
    "                                    scores.append(model.score(X[val],Y[val])) \n",
    "                                \n",
    "                                print(\"Fold Accuracy: \", scores[-1])\n",
    "\n",
    "                        avg_acc = np.asarray(scores).mean()\n",
    "\n",
    "                        print(\"-------------------------- RESULTS -------------------------- \")\n",
    "\n",
    "                        print(\"average 5-fold cross val accuracy: \", avg_acc)\n",
    "\n",
    "                        if avg_acc > best_acc:\n",
    "                            best_acc = avg_acc\n",
    "                            opt_params[\"units\"] = units\n",
    "                            opt_params[\"drop\"] = drop\n",
    "                            opt_params[\"lr\"] = lr\n",
    "\n",
    "                            \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\"Best Params:\")\n",
    "    print(\"LR: \",opt_params[\"lr\"], \" | Units: \", opt_params[\"units\"], \" | Dropout: \",opt_params[\"drop\"])\n",
    "    print(\" \")\n",
    "    print(\"Best Accuracy: \", best_acc)\n",
    "\n",
    "    return opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea362b7a",
   "metadata": {},
   "source": [
    "## PTB Dataset Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanill_ptb_opt_params = rnn_grid_search(name=\"ptb\", model=\"vanilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b037e",
   "metadata": {},
   "source": [
    "## MIT Dataset Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanill_mit_opt_params = rnn_grid_search(name=\"mit\", model=\"vanilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9111751f",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "***************************************\n",
    "This model replaces the RNN cells in the Vanilla RNN model with LSTM cells. Calling the same function with new model:\n",
    "\n",
    "## PTB Dataset Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ptb_opt_params = rnn_grid_search(name=\"ptb\", model=\"lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97faa602",
   "metadata": {},
   "source": [
    "## MIT Dataset Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mit_opt_params = rnn_grid_search(name=\"mit\", model=\"lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b65422",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM \n",
    "***************************************\n",
    "In this model, the bidirectional version of the LSTM cell is used and combined with a variable number of dense layers. We expect this model to capture patters in the non-causal direction as well, potentially improving on the performance of the unidirectional version.\n",
    "\n",
    "Grid search function for Bidirectional LSTM based Model\n",
    "When fine tuning this model, instead of exploring regularization thorugh dropout, determining the optimal number of fully connected layers at the end as well as the number of sequential bidirectional LSTM cells is chosen as the method to change capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidir_lstm_grid_search(name=\"ptb\"):\n",
    "\n",
    "    #optimizer and other unit number options were discarded as grid search takes too long\n",
    "    unit_nums = [ 100, 150]\n",
    "    learning_rates = [0.0001, 0.00005]\n",
    "    num_dense = [2,4]\n",
    "    num_cells = [2,4]\n",
    "    \n",
    "    batch = 200\n",
    "    epochs = 100\n",
    "    optim = \"adam\"\n",
    "    drop = 0\n",
    "\n",
    "    opt_params = {}\n",
    "    best_AUC = 0\n",
    "    best_acc = 0\n",
    "    \n",
    "    (X,Y) = (X_ptbdb, Y_ptbdb) if name==\"ptb\" else (X_mitbih, Y_mitbih)\n",
    "\n",
    "    for n_dense in num_dense:\n",
    "        for n_cells in num_cells:\n",
    "            for units in unit_nums:\n",
    "                for lr in learning_rates:\n",
    "                        print(\"---------------------------------------------------\")\n",
    "                        print(\"Params to evaluate:\")\n",
    "                        print(\"n_dense: \",n_dense, \" | n_cells: \", n_cells, \" | units: \",units, \" | lr: \",lr)\n",
    "\n",
    "                        scores = []\n",
    "\n",
    "                        for train, val in KFold(n_splits=5, shuffle=True).split(X,Y):\n",
    "                            \n",
    "                                print(\"Fold - \", len(scores)+1)\n",
    "\n",
    "                                #callbacks enable early stopping and learning rate reduction\n",
    "                                #depending on validation loss\n",
    "                                early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=15, verbose=1)\n",
    "                                redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=10, verbose=1)\n",
    "                                callbacks_list = [early, redonplat]\n",
    "                                \n",
    "                                with tf.device(device_name):\n",
    "                                \n",
    "                                    # initializing the model\n",
    "                                    #depending on dataset, number of classes determined\n",
    "                                    if name == \"ptb\": \n",
    "                                        model = BiDirLSTM(input_length=X[train].shape[1], \n",
    "                                                          num_units=units, classes=2, callbacks= callbacks_list,\n",
    "                                                          num_cells = n_cells, num_dense = n_dense,\n",
    "                                                          optimizer = optim, dropout= drop, lr=lr)   \n",
    "                                    else:\n",
    "                                        model = BiDirLSTM(input_length=X[train].shape[1], \n",
    "                                                          num_units=units, classes=5, callbacks= callbacks_list,\n",
    "                                                          num_cells = n_cells, num_dense = n_dense,\n",
    "                                                          optimizer = optim, dropout= drop, lr=lr)        \n",
    "\n",
    "                                    # training the model\n",
    "                                    model.fit(X[train], Y[train], epochs=epochs, batch_size=batch, \n",
    "                                            verbose=0, validation_data = (X[val],Y[val]) )\n",
    "\n",
    "                                    # evaluate validation set\n",
    "                                    scores.append(model.score(X[val],Y[val])) \n",
    "                                \n",
    "                                print(\"Fold Accuracy: \", scores[-1])\n",
    "\n",
    "                        avg_acc = np.asarray(scores).mean()\n",
    "\n",
    "                        print(\"-------------------------- RESULTS -------------------------- \")\n",
    "\n",
    "                        print(\"average 5-fold cross val accuracy: \", avg_acc)\n",
    "\n",
    "                        if avg_acc > best_acc:\n",
    "                            best_acc = avg_acc\n",
    "                            opt_params[\"units\"] = units\n",
    "                            opt_params[\"lr\"] = lr\n",
    "                            opt_params[\"n_cells\"] = n_cells\n",
    "                            opt_params[\"n_dense\"] = n_dense\n",
    "\n",
    "                            \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\"Best Params:\")\n",
    "    print(\"n_dense: \",opt_params[\"n_dense\"], \" | n_cells: \", opt_params[\"n_cells\"], \" | units: \",opt_params[\"units\"], \" | lr: \",opt_params[\"lr\"])\n",
    "    print(\" \")\n",
    "    print(\"Best Accuracy: \", best_acc)\n",
    "\n",
    "    return opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09871ba",
   "metadata": {},
   "source": [
    "## PTB Dataset Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87852085",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidir_ptb_opt_params = bidir_lstm_grid_search(name=\"ptb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449fc9e",
   "metadata": {},
   "source": [
    "## MIT Dataset Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidir_mit_opt_params = bidir_lstm_grid_search(name=\"mit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955fcd5",
   "metadata": {},
   "source": [
    "# ConvLSTM Model\n",
    "***************************************\n",
    "This model aims to combine the spacial feature extraction capability of convolution layers with the sequential nature of the LSTM cells. Therefore, the number of convolutional layers becomes a parameter to be tuned. To keep the number of tuned hyperparameters managable, dropout and optimizer are given as fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlstm_grid_search(name=\"ptb\"):\n",
    "\n",
    "    #optimizer and other unit number options were discarded as grid search takes too long\n",
    "    unit_nums = [ 100, 150]\n",
    "    learning_rates = [0.001, 0.0001]\n",
    "    num_dense = [2,4]\n",
    "    num_conv = [2,4]\n",
    "    \n",
    "    batch = 200\n",
    "    epochs = 100\n",
    "    optim = \"adam\"\n",
    "    drop = 0.5\n",
    "\n",
    "    opt_params = {}\n",
    "    best_AUC = 0\n",
    "    best_acc = 0\n",
    "    \n",
    "    (X,Y) = (X_ptbdb, Y_ptbdb) if name==\"ptb\" else (X_mitbih, Y_mitbih)\n",
    "\n",
    "    for n_dense in num_dense:\n",
    "        for n_conv in num_conv:\n",
    "            for units in unit_nums:\n",
    "                for lr in learning_rates:\n",
    "                        print(\"---------------------------------------------------\")\n",
    "                        print(\"Params to evaluate:\")\n",
    "                        print(\"n_dense: \",n_dense, \" | n_conv: \", n_conv, \" | units: \",units, \" | lr: \",lr)\n",
    "\n",
    "                        scores = []\n",
    "\n",
    "                        for train, val in KFold(n_splits=5, shuffle=True).split(X,Y):\n",
    "                            \n",
    "                                print(\"Fold - \", len(scores)+1)\n",
    "\n",
    "                                #callbacks enable early stopping and learning rate reduction\n",
    "                                #depending on validation loss\n",
    "                                early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=15, verbose=1)\n",
    "                                redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=10, verbose=1)\n",
    "                                callbacks_list = [early, redonplat]\n",
    "                                \n",
    "                                with tf.device(device_name):\n",
    "                                \n",
    "                                    # initializing the model\n",
    "                                    #depending on dataset, number of classes determined\n",
    "                                    if name == \"ptb\": \n",
    "                                        model = ConvLSTM(input_length=X[train].shape[1], \n",
    "                                                         num_units=units, classes=2, callbacks= callbacks_list,\n",
    "                                                         num_conv = n_conv, num_dense = n_dense,\n",
    "                                                         optimizer = optim, dropout= drop, lr=lr)   \n",
    "                                    else:\n",
    "                                        model = ConvLSTM(input_length=X[train].shape[1], \n",
    "                                                         num_units=units, classes=5, callbacks= callbacks_list,\n",
    "                                                         num_conv = n_conv, num_dense = n_dense,\n",
    "                                                         optimizer = optim, dropout= drop, lr=lr) \n",
    "\n",
    "                                    # training the model\n",
    "                                    model.fit(X[train], Y[train], epochs=epochs, batch_size=batch, \n",
    "                                            verbose=0, validation_data = (X[val],Y[val]) )\n",
    "\n",
    "                                    # evaluate validation set\n",
    "                                    scores.append(model.score(X[val],Y[val]))\n",
    "                                \n",
    "                                print(\"Fold Accuracy: \", scores[-1])\n",
    "\n",
    "                        avg_acc = np.asarray(scores).mean()\n",
    "\n",
    "                        print(\"-------------------------- RESULTS -------------------------- \")\n",
    "\n",
    "                        print(\"average 5-fold cross val accuracy: \", avg_acc)\n",
    "\n",
    "                        if avg_acc > best_acc:\n",
    "                            best_acc = avg_acc\n",
    "                            opt_params[\"units\"] = units\n",
    "                            opt_params[\"lr\"] = lr\n",
    "                            opt_params[\"n_conv\"] = n_conv\n",
    "                            opt_params[\"n_dense\"] = n_dense\n",
    "\n",
    "                            \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\"Best Params:\")\n",
    "    print(\"n_dense: \",opt_params[\"n_dense\"], \" | n_conv: \", opt_params[\"n_conv\"], \" | units: \",opt_params[\"units\"], \" | lr: \",opt_params[\"lr\"])\n",
    "    print(\" \")\n",
    "    print(\"Best Accuracy: \", best_acc)\n",
    "\n",
    "    return opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6863939",
   "metadata": {},
   "source": [
    "## PTB Dataset Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm_ptb_opt_params = convlstm_grid_search(name=\"ptb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57187583",
   "metadata": {},
   "source": [
    "## MIT Dataset Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf10552",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm_mit_opt_params = convlstm_grid_search(name=\"mit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
