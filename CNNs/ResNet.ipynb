{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76212a2a",
   "metadata": {},
   "source": [
    "# Task 2: ResNet\n",
    "\n",
    "In the following ResNet models for ECG heartbeat classification are trained. We trained different models from data from the [MIT-BIH Arrythmia Database](https://physionet.org/content/mitdb/1.0.0/) and [PTB Diagnostic ECG Database](https://physionet.org/physiobank/database/ptbdb/). \n",
    "\n",
    "First three different net-architectures are compared with a 5-fold cross validation in order to determine the best structure among these. ResNetSmall has 5 residual blocks and 16 filters in each layer, whereas ResNetStandard has 32 filters in each layer. ResNetDS is a ResNet model with downsampling. It consists of 7 residual blocks with an increasing number of filters.  \n",
    "\n",
    "Second, the hyperparameters are tuned with a grid search. Due to computational reasons we did the grid search on the PTB data and then used the optimal parameters for the MIT-BIH data too. Then the final model is trained with all available training data and the classes for the test set are predicted. \n",
    "\n",
    "Further information can be found in the corresponding section of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939fe66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras import losses, activations, models\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f7c62",
   "metadata": {},
   "source": [
    "# MITBIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c47d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c936a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best performing resnet architecture\n",
    "accs = {\n",
    "    \"ResNet_small\" : [],\n",
    "    \"ResNet_standard\" : [],\n",
    "    \"ResNet_downsample\" : []\n",
    "}\n",
    "\n",
    "for fold, (train, val) in enumerate(KFold(n_splits=5, shuffle=True,random_state = 123).split(X,Y)):\n",
    "    file_path_small = f\"Results/ResNet_small_MITBIH.h5\"\n",
    "    checkpoint_small = ModelCheckpoint(file_path_small, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_small = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_small = [checkpoint_small, early_small] \n",
    "\n",
    "    file_path_standard = f\"Results/ResNet_standard_MITBIH.h5\"\n",
    "    checkpoint_standard = ModelCheckpoint(file_path_standard, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_standard = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_standard = [checkpoint_standard, early_standard] \n",
    "\n",
    "    file_path_ds = f\"Results/ResNet_DS_MITBIH.h5\"\n",
    "    checkpoint_ds = ModelCheckpoint(file_path_ds, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_ds = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_ds = [checkpoint_ds, early_ds]\n",
    "\n",
    "    resnet_small = ResNetSmall(5, optimizer=optimizers.Adam(0.001), callbacks=callbacks_list_small)\n",
    "    resnet_standard = ResNetStandard(5,0.1,optimizer=optimizers.Adam(0.001), callbacks=callbacks_list_standard)\n",
    "    resnet_ds = ResNetDS(5,optimizer=optimizers.Adam(0.001), callbacks=callbacks_list_ds)\n",
    "\n",
    "    resnet_small.fit(X[train], Y[train], epochs=1, batch_size=128, verbose=1, validation_data = (X[val],Y[val]) )\n",
    "    resnet_standard.fit(X[train], Y[train], epochs=1, batch_size=128, verbose=1, validation_data = (X[val],Y[val]) )\n",
    "    resnet_ds.fit(X[train], Y[train], epochs=1, batch_size=128, verbose=1, validation_data = (X[val],Y[val]) )\n",
    "\n",
    "    accs[\"ResNet_small\"].append(resnet_small.score(X[val],Y[val]))\n",
    "    accs[\"ResNet_standard\"].append(resnet_standard.score(X[val],Y[val]))\n",
    "    accs[\"ResNet_downsample\"].append(resnet_ds.score(X[val],Y[val]))\n",
    "\n",
    "    with open(\"Results/ResNet_CV_results_MITBIH.json\", \"w\") as outfile:\n",
    "        json.dump(accs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ResNet_CV_results_MITBIH.json')\n",
    "results_mitbih = json.load(f)\n",
    "for model in results_mitbih.keys():\n",
    "print(\"Architecture\", model)\n",
    "mean_acc = sum(elt for elt in results_mitbih[model])/len(results_mitbih[model])\n",
    "print(f\"mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8299d94",
   "metadata": {},
   "source": [
    "Best performing model: Architecture ResNet_Standard\n",
    "\n",
    "mean loss: **0.05553194060921669** \t mean acc: **0.9836557745933533**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c35bb",
   "metadata": {},
   "source": [
    "## Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_resnet = f\"Results/ResNet_MITBIH.h5\"\n",
    "checkpoint_resnet = ModelCheckpoint(file_path_resnet, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "early_resnet = EarlyStopping(monitor='val_acc', patience=10)\n",
    "callbacks_list_resnet = [checkpoint_resnet, early_resnet] \n",
    "resnet_model = ResNetStandard(5,0.1,optimizer=optimizers.RMSprop(0.001), callbacks=callbacks_list_resnet)\n",
    "resnet_model.fit(X,Y, epochs=100, batch_size=128, verbose=2, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b60f1",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.load_weights(\"Results/ResNet_MITBIH.h5\")\n",
    "pred_test = resnet_model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test,average=\"macro\")\n",
    "print(f\"Test f1 score : {f1} \")\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "print(f\"Test accuracy : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4affa2f",
   "metadata": {},
   "source": [
    "# PTBDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_1 = pd.read_csv(\"../input/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../input/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e54397",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = {\n",
    "    \"init_small_ResNet\" : [],\n",
    "    \"init_ResNet\" : [],\n",
    "    \"downsample_ResNet\" : []\n",
    "}\n",
    "\n",
    "for fold, (train, val) in enumerate(KFold(n_splits=5, shuffle=True,random_state = 123).split(X,Y)):\n",
    "    \n",
    "    file_path_small = f\"Results/ResNet_small_PTBDB.h5\"\n",
    "    checkpoint_small = ModelCheckpoint(file_path_small, monitor='val_acc', verbose=0, save_best_only=True, mode='max')    \n",
    "    early_small = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_small = [checkpoint_small, early_small] \n",
    "\n",
    "    file_path_standard = f\"Results/ResNet_standard_PTBDB.h5\"\n",
    "    checkpoint_standard = ModelCheckpoint(file_path_standard, monitor='val_acc', verbose=0, save_best_only=True, mode='max')    \n",
    "    early_standard = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_standard = [checkpoint_standard, early_standard] \n",
    "\n",
    "    file_path_ds = f\"Results/ResNet_DS_PTBDB.h5\"\n",
    "    checkpoint_ds = ModelCheckpoint(file_path_ds, monitor='val_acc', verbose=0, save_best_only=True, mode='max')    \n",
    "    early_ds = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_ds = [checkpoint_ds, early_ds]\n",
    "\n",
    "    resnet_small = ResNetSmall(1, optimizer=optimizers.Adam(0.001))\n",
    "    resnet_standard = ResNetStandard(1,0.1,optimizer=optimizers.Adam(0.001))\n",
    "    resnet_ds = ResNetDS(1,optimizer=optimizers.Adam(0.001))\n",
    "\n",
    "    resnet_small.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, callbacks=callbacks_list_small, validation_data = (X[val],Y[val]) )\n",
    "    resnet_standard.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, callbacks=callbacks_list_standard, validation_data = (X[val],Y[val]) )\n",
    "    resnet_ds.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, callbacks=callbacks_list_ds, validation_data = (X[val],Y[val]) )\n",
    "\n",
    "    accs[\"ResNet_small\"].append(resnet_small.score(X[val],Y[val]))\n",
    "    accs[\"ResNet_standard\"].append(resnet_standard.score(X[val],Y[val]))\n",
    "    accs[\"ResNet_downsample\"].append(resnet_ds.score(X[val],Y[val]))\n",
    "\n",
    "    \n",
    "    with open(\"Results/ResNet_CV_results_PTBDB.json\", \"w\") as outfile:\n",
    "        json.dump(accs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d42784",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Results/ResNet_CV_results_PTBDB.json')\n",
    "results_ptbdb = json.load(f)\n",
    "means_ptbdb = []\n",
    "for model in results_ptbdb.keys():\n",
    "    print(\"Architecture\", model)\n",
    "    mean_acc = sum(elt for elt in results_ptbdb[model])/len(results_ptbdb[model])\n",
    "    print(f\"mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03f967",
   "metadata": {},
   "source": [
    "Best performing model: Architecture ResNet_Standard\n",
    "\n",
    "mean loss: **0.042983403429389** \t mean acc: **0.9849681377410888**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc9f22",
   "metadata": {},
   "source": [
    "## Hyperparametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81550a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = {}\n",
    "\n",
    "dropout_rate = [0.1,0.3]\n",
    "opts = [\"Adam\", \"SGD\", \"rmsprop\"]\n",
    "learning_rates = [(\"const\", 0.0001), (\"const\", 0.001), (\"exponential\", 0.9), (\"exponential\", 0.1), (\"poly\", 1),(\"poly\", 5)]\n",
    "\n",
    "for dr in dropout_rate:\n",
    "    for opt in opts: \n",
    "        for mode,factor in learning_rates:\n",
    "            if mode == \"const\":\n",
    "                lr = factor\n",
    "            elif mode==\"exponential\": \n",
    "                lr = optimizers.schedules.ExponentialDecay(initial_learning_rate=0.005,decay_steps=1000,decay_rate=factor)\n",
    "            else:\n",
    "                lr = optimizers.schedules.PolynomialDecay(initial_learning_rate=0.01,decay_steps=1000,power=factor)\n",
    "            if opt== \"Adam\":\n",
    "                optimizer = optimizers.Adam(learning_rate = lr)\n",
    "            elif opt == \"SGD\":\n",
    "                optimizer = optimizers.SGD(learning_rate = lr)\n",
    "            elif opt == \"rmsprop\":\n",
    "                optimizer = optimizers.RMSprop(learning_rate = lr)\n",
    "            \n",
    "            grid_search_results[f\"{dr}_{opt}_{mode}_{factor}\"] = []\n",
    "            \n",
    "            for fold, (train, val) in enumerate(KFold(n_splits=3, shuffle=True,random_state = 123).split(X,Y)):\n",
    "                print(f\"FOLD: {fold} DR {dr} OPT {opt} MODDE {mode} FACTOR {factor}\")\n",
    "                file_path_standard = f\"Results/ResNet_PTBDB_Hyperparam.h5\"\n",
    "                checkpoint_standard = ModelCheckpoint(file_path_standard, monitor='val_acc', verbose=0, save_best_only=True, mode='max')    \n",
    "                early_standard = EarlyStopping(monitor='val_acc', patience=7)\n",
    "                callbacks_list_standard = [checkpoint_standard, early_standard] \n",
    "                resnet_standard = ResNetStandard(1,dr,optimizer=optimizer, callbacks=callbacks_list_init)\n",
    "\n",
    "                resnet_standard.fit(X[train], Y[train], epochs=1, batch_size=128, verbose=1, validation_data = (X[val],Y[val]))\n",
    "    \n",
    "                grid_search_results[f\"{dr}_{opt}_{mode}_{factor}\"].append(resnet_standard.score(X[val],Y[val]))\n",
    "\n",
    "                with open(\"Results/ResNet_Hyperparam_CV_3_results_ptbdb.json\", \"w\") as outfile:\n",
    "                    json.dump(grid_search_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72811006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.1_Adam_const_0.0001', 0.5779443159068189)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('Results/ResNet_Hyperparam_CV_3_results_ptbdb.json')\n",
    "grid_search_results = json.load(f)\n",
    "means = []\n",
    "for k in grid_search_results.keys():\n",
    "    mean_acc = sum(elt for elt in grid_search_results[k])/len(grid_search_results[k])\n",
    "    means.append((k, mean_acc))\n",
    "grid_search_results\n",
    "means.sort(reverse = True)\n",
    "means[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c1774",
   "metadata": {},
   "source": [
    "Based on the grid search the optimal parameters for the model are: \n",
    "\n",
    "dropout rate: **0.1** \n",
    "\n",
    "optimizer: **RMSProp**\n",
    "\n",
    "learning rate: **constant of 0.001***\n",
    "\n",
    "These parameters obtained performances of (average loss,  average accuracy): \n",
    "\n",
    "**(0.056621051083008446, 0.9811009367307028)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5645f9",
   "metadata": {},
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd49621",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_standard = f\"Results/ResNet_PTBDB.h5\"\n",
    "checkpoint_standard = ModelCheckpoint(file_path_standard, monitor='val_acc', verbose=0, save_best_only=True, mode='max')    \n",
    "early_standard = EarlyStopping(monitor='val_acc', patience=7)\n",
    "callbacks_list_standard = [checkpoint_standard, early_standard] \n",
    "resnet_standard = ResNetStandard(1,dr,optimizer=optimizer, callbacks=callbacks_list_standard)\n",
    "resnet_standard.fit(X, Y, epochs=100, batch_size=128, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b287ea",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_standard.load_weights(\"Results/ResNet_PTBDB.h5\")\n",
    "pred_test = resnet_standard.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy : %s \"% acc)\n",
    "\n",
    "auroc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test AUROC : %s \"% auroc)\n",
    "\n",
    "auprc = average_precision_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test AUPRC : %s \"% auprc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4HC1",
   "language": "python",
   "name": "ml4hc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
