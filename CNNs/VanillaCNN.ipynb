{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eb1c03",
   "metadata": {},
   "source": [
    "# Task 1: Vanilla CNN\n",
    "\n",
    "In the following, vanilla CNN for ECG heartbeat classification are trained. We trained different models from data from the [MIT-BIH Arrythmia Database](https://physionet.org/content/mitdb/1.0.0/) and [PTB Diagnostic ECG Database](https://physionet.org/physiobank/database/ptbdb/). \n",
    "\n",
    "First three different net-architectures are compared with a 5-fold cross validation in order to determine the best structure among these. We compare the architecture from the baseline (Baseline-Class) to a [VGG-net similar architecture](https://www.hindawi.com/journals/jhe/2021/7167891/) (DoubleConv-Class) and a alternating convolutional and maxpool layer architecture (VanillaCNN-Class).\n",
    "\n",
    "\n",
    "Second, the hyperparameters are tuned with a grid search. Then the final model is trained with all available training data and the classes for the test set are predicted. For the MIT-BIH data, the VanillaCNN-model is further evaluated and on the PTBDB data, the DoubleConv-model is further evaluated. \n",
    "\n",
    "Further information can be found in the corresponding section of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras import losses, activations, models\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d495e22",
   "metadata": {},
   "source": [
    "## MIT-BIH Arryhtmia Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Different VanillaCNN structures\n",
    "accs = {\n",
    "    \"basemodel\" : [],\n",
    "    \"doubleconv_model\" : [],\n",
    "    \"init_model\" : []\n",
    "}\n",
    "\n",
    "for fold, (train, val) in enumerate(KFold(n_splits=5, shuffle=True,random_state = 123).split(X,Y)):\n",
    "    \n",
    "    # create callback lists for different models\n",
    "    file_path_bl = f\"Results/baseline_cnn_mitbih.h5\"\n",
    "    checkpoint_bl = ModelCheckpoint(file_path_bl, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_bl = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_bl = [checkpoint_bl, early_bl] \n",
    "    \n",
    "    file_path_doubleconv = f\"Results/doubleconv_cnn_mitbih.h5\"\n",
    "    checkpoint_doubleconv = ModelCheckpoint(file_path_doubleconv, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_doubleconv = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_doubleconv = [checkpoint_doubleconv, early_doubleconv] \n",
    "    \n",
    "    file_path_init = f\"Results/init_cnn_mitbih.h5\"\n",
    "    checkpoint_init = ModelCheckpoint(file_path_init, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_init = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_init = [checkpoint_init, early_init]\n",
    "    \n",
    "    baseline_model = Baseline(5, callbacks=callbacks_list_bl)\n",
    "    doubleconv_model = DoubleConvCNN(5,0.1, optimizers.Adam(0.001),callbacks=callbacks_list_doubleconv)\n",
    "    init_model = VanillaCNN(5,0.1, optimizers.Adam(0.001), callbacks=callbacks_list_init)\n",
    "    \n",
    "    # train models\n",
    "    baseline_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=2,  validation_data = (X[val],Y[val]) )\n",
    "    doubleconv_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=2, validation_data = (X[val],Y[val]) )\n",
    "    init_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=2, validation_data = (X[val],Y[val]) )\n",
    "    \n",
    "    # evaluate models\n",
    "    accs[\"basemodel\"].append(baseline_model.score(X[val],Y[val]))\n",
    "    accs[\"doubleconv_model\"].append(doubleconv_model.score(X[val],Y[val]))\n",
    "    accs[\"init_model\"].append(init_model.score(X[val],Y[val]))\n",
    "    \n",
    "    with open(\"Results/CNN_CV_results_MITBIH.json\", \"w\") as outfile:\n",
    "        json.dump(accs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Results/CNN_CV_results_MITBIH.json')\n",
    "results_mitbih = json.load(f)\n",
    "for model in results_mitbih.keys():\n",
    "    print(\"Architecture\", model)\n",
    "    mean_acc = sum(elt for elt in results_mitbih[model])/len(results_mitbih[model])\n",
    "    print(f\"mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b75c9a",
   "metadata": {},
   "source": [
    "The CNN architecture from the basemodel is best performing, out of the three different architectures. However, we continue with the Conv-MaxPool model (second best performing model), because the basemodel might already be hyperparameter tuned and we assume that the objective of the VanillaCNN task is not to reproduce the basemodel. The Conv-MaxPool model obtained the following performances:\n",
    "\n",
    "**mean loss: 0.06200777292251587** \t \n",
    "\n",
    "**mean acc: 0.9842497110366821**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35590c9",
   "metadata": {},
   "source": [
    "### Hyperparametertuning\n",
    "The following hyperparameters (dropout rate, learning_rate, optimizer, activation function, decay) are tuned with a 5-fold CV grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = {}\n",
    "\n",
    "dropout_rate = [0.1,0.3]\n",
    "opts = [\"Adam\", \"SGD\", \"rmsprop\"]\n",
    "learning_rates = [(\"const\", 0.0001), (\"const\", 0.001), (\"const\",0.01), (\"lr_schedule\", 0.9), (\"lr_schedule\", 0.1), (\"lr_schedule\", 0.01)]\n",
    "\n",
    "for dr in dropout_rate:\n",
    "    for opt in opts: \n",
    "        for mode,factor in learning_rates:\n",
    "            if mode == \"const\":\n",
    "                lr = factor\n",
    "            else: \n",
    "                lr = optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=1000,decay_rate=factor)\n",
    "            if opt== \"Adam\":\n",
    "                optimizer = optimizers.Adam(learning_rate = lr)\n",
    "            elif opt == \"SGD\":\n",
    "                optimizer = optimizers.SGD(learning_rate = lr)\n",
    "            elif opt == \"rmsprop\":\n",
    "                optimizer = optimizers.RMSprop(learning_rate = lr)\n",
    "            \n",
    "            grid_search_results[f\"{dr}_{opt}_{mode}_{factor}\"] = []\n",
    "            \n",
    "            for fold, (train, val) in enumerate(KFold(n_splits=3, shuffle=True,random_state = 123).split(X,Y)):\n",
    "                # create callback lists for different models\n",
    "                file_path_vanillacnn = f\"Results/init_cnn_mitbih_grid_search.h5\"\n",
    "                checkpoint_vanillacnn = ModelCheckpoint(file_path_init, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "                early_vanillacnn = EarlyStopping(monitor='val_acc', patience=7)\n",
    "                callbacks_list_vanillacnn = [checkpoint_vanillacnn, early_vanillacnn]\n",
    "                \n",
    "                vanillacnn_model = VanillaCNN(5, dr, optimizer, callbacks=callbacks_list_vanillacnn)\n",
    "                vanillacnn_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=2, validation_data = (X[val],Y[val]) )\n",
    "    \n",
    "                grid_search_results[f\"{dr}_{opt}_{mode}_{factor}\"].append(vanillacnn_model.score(X[val],Y[val]))\n",
    "\n",
    "                with open(\"Results/CNN_Hyperparam_CV_results_MITBIH.json\", \"w\") as outfile:\n",
    "                    json.dump(grid_search_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75399b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Results/CNN_Hyperparam_CV_results_MITBIH.json')\n",
    "grid_search_results = json.load(f)\n",
    "means = []\n",
    "for k in grid_search_results.keys():\n",
    "    mean_acc = sum(eltfor elt in grid_search_results[k])/len(grid_search_results[k])\n",
    "    means.append((k, mean_acc))\n",
    "\n",
    "means.sort(key=lambda a: (-a))\n",
    "means[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb3634",
   "metadata": {},
   "source": [
    "Based on the grid search the optimal parameters for the model are: \n",
    "\n",
    "dropout rate: **0.1** \n",
    "\n",
    "optimizer: **Adam**\n",
    "\n",
    "learning rate: **constant of 0.001***\n",
    "\n",
    "These parameters obtained performances of (average loss,  average accuracy): \n",
    "\n",
    "**(0.054875085751215615, 0.9846951365470886)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398394b7",
   "metadata": {},
   "source": [
    "### Train Final Model\n",
    "\n",
    "The final model with parameters set to the optimal values from the grid search is trained on all given training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_vanillacnn = f\"Results/VanillaCNN_MITBIH.h5\"\n",
    "checkpoint_vanillacnn = ModelCheckpoint(file_path_vanillacnn, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "early_init_vanillacnn = EarlyStopping(monitor='val_acc', patience=7)\n",
    "callbacks_list_vanillacnn = [checkpoint_vanillacnn, early_init_vanillacnn]\n",
    "lr = 0.001\n",
    "optimizer = optimizers.Adam(learning_rate = lr)\n",
    "vanillacnn_model = VanillaCNN(5,0.1, optimizer, callbacks=callbacks_list_vanillacnn)\n",
    "vanillacnn_model.fit(X, Y, epochs=200, batch_size=128, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a239f7d",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanillacnn_model.load_weights(\"Results/VanillaCNN_MITBIH.h5\")\n",
    "pred_test = vanillacnn_model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test,average=\"macro\")\n",
    "print(f\"Test f1 score : {f1} \")\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "print(f\"Test accuracy : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055e07d",
   "metadata": {},
   "source": [
    "mean f1 0.9091180122085432, var f1: 1.0683676232951701e-05\n",
    "\n",
    "\n",
    "mean acc 0.983957610085876, var acc: 6.00426077167262e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6184cd7",
   "metadata": {},
   "source": [
    "## PTB Diagonstic ECG Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_1 = pd.read_csv(\"../input/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../input/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = {\n",
    "    \"basemodel\" : [],\n",
    "    \"doubleconv_model\" : [],\n",
    "    \"init_model\" : []\n",
    "}\n",
    "\n",
    "for fold, (train, val) in enumerate(KFold(n_splits=5, shuffle=True,random_state = 123).split(X,Y)):\n",
    "    # create callback lists for different models\n",
    "    file_path_bl = f\"Results/baseline_cnn_ptbdb.h5\"\n",
    "    checkpoint_bl = ModelCheckpoint(file_path_bl, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_bl = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_bl = [checkpoint_bl, early_bl] \n",
    "    \n",
    "    file_path_doubleconv = f\"Results/doubleconv_cnn_ptbdb.h5\"\n",
    "    checkpoint_doubleconv = ModelCheckpoint(file_path_doubleconv, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_doubleconv = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_doubleconv = [checkpoint_doubleconv, early_doubleconv] \n",
    "    \n",
    "    file_path_init = f\"Results/init_cnn_ptbdb.h5\"\n",
    "    checkpoint_init = ModelCheckpoint(file_path_init, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "    early_init = EarlyStopping(monitor='val_acc', patience=7)\n",
    "    callbacks_list_init = [checkpoint_init, early_init]\n",
    "    \n",
    "    baseline_model = Baseline(1, callbacks=callbacks_list_bl)\n",
    "    doubleconv_model = DoubleConvCNN(1,0.1, optimizers.Adam(0.001), callbacks=callbacks_list_doubleconv)\n",
    "    init_model = VanillaCNN(1,0.1, optimizers.Adam(0.001), callbacks=callbacks_list_init)\n",
    "    \n",
    "    # train models\n",
    "    baseline_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, validation_data = (X[val],Y[val]) )\n",
    "    doubleconv_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, validation_data = (X[val],Y[val]) )\n",
    "    init_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, validation_data = (X[val],Y[val]) )\n",
    "    \n",
    "    # evaluate models\n",
    "    accs[\"basemodel\"].append(baseline_model.score(X[val],Y[val]))\n",
    "    accs[\"doubleconv_model\"].append(doubleconv_model.score(X[val],Y[val]))\n",
    "    accs[\"init_model\"].append(init_model.score(X[val],Y[val]))\n",
    "    \n",
    "    with open(\"Results/CNN_CV_results_PTBDB.json\", \"w\") as outfile:\n",
    "        json.dump(accs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Results/CNN_CV_results_PTBDB.json')\n",
    "results_ptbdb = json.load(f)\n",
    "means_ptbdb = []\n",
    "for model in results_ptbdb.keys():\n",
    "    print(\"Architecture\", model)\n",
    "    mean_acc = sum(elt for elt in results_ptbdb[model])/len(results_ptbdb[model])\n",
    "    print(f\"mean acc: {mean_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae40c91",
   "metadata": {},
   "source": [
    "The CNN architecture from the basemodel is best performing, out of the three different architectures. However, we continue with the DoubleConv model (second best performing model), because the basemodel might already be hyperparameter tuned and we assume that the objective of the VanillaCNN task is not to reproduce the basemodel. The DoubleConv model obtained the following performances:\n",
    "\n",
    "**mean loss: 0.05904214382171631** \t \n",
    "\n",
    "**mean acc: 0.9812728762626648**\n",
    "\n",
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = {}\n",
    "\n",
    "dropout_rate = [0.1,0.3]\n",
    "\n",
    "opts = [\"Adam\", \"SGD\", \"rmsprop\"]\n",
    "learning_rates = [(\"const\", 0.0001), (\"const\", 0.001), (\"const\",0.01), (\"lr_schedule\", 0.9), (\"lr_schedule\", 0.1), (\"lr_schedule\", 0.01)]\n",
    "\n",
    "for dr in dropout_rate:\n",
    "    for opt in opts: \n",
    "        for mode,factor in learning_rates:\n",
    "            if mode == \"const\":\n",
    "                lr = factor\n",
    "            else: \n",
    "                lr = optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=1000,decay_rate=factor)\n",
    "            \n",
    "            if opt== \"Adam\":\n",
    "                optimizer = optimizers.Adam(learning_rate = lr)\n",
    "            elif opt == \"SGD\":\n",
    "                optimizer = optimizers.SGD(learning_rate = lr)\n",
    "            elif opt == \"rmsprop\":\n",
    "                optimizer = optimizers.RMSprop(learning_rate = lr)\n",
    "            \n",
    "            grid_search_results[f\"{dr}_{opt}_{mode}_{factor}\"] = []\n",
    "            \n",
    "            for fold, (train, val) in enumerate(KFold(n_splits=3, shuffle=True,random_state = 123).split(X,Y)):\n",
    "                file_path_doubleconv = f\"Results/doubleconv_cnn_ptbdb.h5\"\n",
    "                checkpoint_doubleconv = ModelCheckpoint(file_path_doubleconv, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "                early_doubleconv = EarlyStopping(monitor='val_acc', patience=7)\n",
    "                callbacks_list_doubleconv = [checkpoint_doubleconv, early_doubleconv] \n",
    "\n",
    "                doubleconv_model = DoubleConvCNN(1,dr, optimizer)\n",
    "                doubleconv_model.fit(X[train], Y[train], epochs=100, batch_size=128, verbose=1, callbacks=callbacks_list_doubleconv, validation_data = (X[val],Y[val]) )\n",
    "    \n",
    "                grid_search_results[f\"{dr}_{opt}_{mode}_{factor}\"].append(doubleconv_model.score(X[val],Y[val]))\n",
    "\n",
    "                with open(\"Results/CNN_Hyperparam_CV_results_PTBDB.json\", \"w\") as outfile:\n",
    "                    json.dump(grid_search_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Results/CNN_Hyperparam_CV_results_PTBDB.json')\n",
    "grid_search_results = json.load(f)\n",
    "means = []\n",
    "for k in grid_search_results.keys():\n",
    "    mean_acc = sum(elt for elt in grid_search_results[k])/len(grid_search_results[k])\n",
    "    means.append((k, mean_acc))\n",
    "\n",
    "means.sort(key=lambda a: (-a))\n",
    "means[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8ec70",
   "metadata": {},
   "source": [
    "Based on the grid search the optimal parameters for the model are: \n",
    "\n",
    "dropout rate: **0.1** \n",
    "\n",
    "optimizer: **Adam**\n",
    "\n",
    "learning rate: **decay with decay rate of 0.9***\n",
    "\n",
    "These parameters obtained performances of (average loss,  average accuracy): \n",
    "\n",
    "**(0.056583555042743684, 0.9809292674064636)**\n",
    "\n",
    "\n",
    "### Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8218463",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_doubleconv = f\"Results/VanillaCNN_PTBDB.h5\"\n",
    "checkpoint_doubleconv = ModelCheckpoint(file_path_doubleconv, monitor='val_acc', verbose=2, save_best_only=True, mode='max')    \n",
    "early_doubleconv = EarlyStopping(monitor='val_acc', patience=7)\n",
    "callbacks_list_doubleconv = [checkpoint_doubleconv, early_doubleconv] \n",
    "\n",
    "lr = optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=1000,decay_rate=0.9)\n",
    "optimizer = optimizers.Adam(learning_rate = lr)\n",
    "doubleconv_model = DoubleConvCNN(1,0.1, optimizer,callbacks=callbacks_list_doubleconv)\n",
    "\n",
    "doubleconv_model.fit(X, Y, epochs=100, batch_size=128, verbose=1,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864513af",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubleconv_model.load_weights(\"Results/VanillaCNN_PTBDB.h5\")\n",
    "pred_test = doubleconv_model.predict(X_test)\n",
    "#pred_test = (pred_test>0.5).astype(np.int8)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy : %s \"% acc)\n",
    "\n",
    "auroc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test AUROC : %s \"% auroc)\n",
    "\n",
    "auprc = average_precision_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test AUPRC : %s \"% auprc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4HC1",
   "language": "python",
   "name": "ml4hc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
